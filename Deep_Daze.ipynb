{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Daze",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Q6NGIB2FaQ"
      },
      "source": [
        "**Restart after running this cell!**\n",
        "\n",
        "You must run this cell and then restart and rerun everything for the PyTorch version to be correct. Otherwise the model will run but not produce any meaningful output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55YJsbFV10i8",
        "outputId": "b358bc57-3877-4ce5-bf7b-2e4db52cef24"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "\n",
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 10.1\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (735.4MB)\n",
            "\u001b[K     |████████████████████████████████| 735.4MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 26.5MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.2+cu101) (7.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45613 sha256=0271200638bd4828b5a4ac29b6c7b278fd50500b6db035571ec8fdd4104a4f11\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "Successfully built ftfy\n",
            "Installing collected packages: torch, torchvision, ftfy\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed ftfy-5.8 torch-1.7.1+cu101 torchvision-0.8.2+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpRu6LTR2LbD",
        "outputId": "9d142056-5418-49be-bd56-5c342901c814"
      },
      "source": [
        "!pip install deep-daze --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deep-daze\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/9f/82723dfd512c4e7bf0552ef86c03b451227fb5c8e045d0ae21221799152a/deep_daze-0.1.23-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from deep-daze) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: ftfy in /usr/local/lib/python3.6/dist-packages (from deep-daze) (5.8)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from deep-daze) (1.7.1+cu101)\n",
            "Collecting siren-pytorch>=0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/2e/c7607f8454ac911ed178c57aa52aa8a981a737379ca32e62d737e4826ff1/siren_pytorch-0.0.7-py3-none-any.whl\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n",
            "\u001b[?25hCollecting einops>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->deep-daze) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.1->deep-daze) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.1->deep-daze) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.1->deep-daze) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from fire->deep-daze) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->deep-daze) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111006 sha256=1eced27d168df85707da8a78ffbdb60070a22889c1e3192a4f06bdb76fa09830\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built fire\n",
            "Installing collected packages: einops, siren-pytorch, fire, deep-daze\n",
            "Successfully installed deep-daze-0.1.23 einops-0.3.0 fire-0.3.1 siren-pytorch-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IPQ_rdA2Sa7",
        "outputId": "58918614-19bb-4729-d537-9d212a584302"
      },
      "source": [
        "from tqdm import trange\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from deep_daze import Imagine\n",
        "\n",
        "TEXT = 'an apple next to a fireplace' #@param {type:\"string\"}\n",
        "NUM_LAYERS = 32 #@param {type:\"number\"}\n",
        "SAVE_EVERY =  20#@param {type:\"number\"}\n",
        "IMAGE_WIDTH = 512 #@param {type:\"number\"}\n",
        "SAVE_PROGRESS = False #@param {type:\"boolean\"}\n",
        "LEARNING_RATE = 1e-5 #@param {type:\"number\"}\n",
        "ITERATIONS = 1050 #@param {type:\"number\"}\n",
        "\n",
        "model = Imagine(\n",
        "    text = TEXT,\n",
        "    num_layers = NUM_LAYERS,\n",
        "    save_every = SAVE_EVERY,\n",
        "    image_width = IMAGE_WIDTH,\n",
        "    lr = LEARNING_RATE,\n",
        "    iterations = ITERATIONS,\n",
        "    save_progress = SAVE_PROGRESS\n",
        ")\n",
        "\n",
        "for epoch in trange(20, desc = 'epochs'):\n",
        "    for i in trange(1000, desc = 'iteration'):\n",
        "        model.train_step(epoch, i)\n",
        "\n",
        "        if i % model.save_every != 0:\n",
        "            continue\n",
        "\n",
        "        filename = TEXT.replace(' ', '_')\n",
        "        image = Image(f'./{filename}.png')\n",
        "        display(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████| 353976522/353976522 [00:11<00:00, 30885420.50it/s]\n",
            "epochs:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "iteration:   0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}